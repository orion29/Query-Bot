{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d925700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7ab1740",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "\n",
    "\n",
    "    user_input : str             # The raw query user sends\n",
    "    optimized_prompt : str       # After prompt cleaning\n",
    "    context : dict                  # Any past conversation context\n",
    "    schema : list                  # Selected DataFrame schema\n",
    "    ambiguity_flags : bool         # If multiple schema/columns matched\n",
    "    pandas_code : str             # Generated code\n",
    "    execution_result : str        # Output after code is run\n",
    "    memory : list                    # Long-term or session memory\n",
    "    agent_status: dict            # Which agents are on/off (important for Q2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b20497bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hello = \"xx\"\n",
    "\n",
    "z = f\"\"\" my name is {hello} \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ee69ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eaf630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9f15bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../prompt/schema_selection.txt', 'r') as f:\n",
    "    prompt_template = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e153da3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = prompt_template.format(\n",
    "    table_schema=table_schema,\n",
    "    user_question=user_question\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08506a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_description_table = pd.DataFrame({\n",
    "    \"column_name\": [\"name\",\"salary\",\"department\",\"department\",\"average_salary\"],\n",
    "    \"column_description\": [\"Name of the person\",\"Annual salary given to the person in lakh per annum\",\"name of the department where the person belongs to\",\"name of the department in the organization\",\"Average salary provided to all the people in the department\"],\n",
    "    \"typical_values\": [\"\",\"\",\"electronics, communication, finance, hr\",\"electronics, communication, finance, hr\",\"\"],\n",
    "    \"table_name\": [\"resource_table\",\"resource_table\",\"resource_table\",\"department_table\",\"department_table\"],\n",
    "    \"table_description\": [\"Table with all the resources present in the office, their salaries and their department\",\"Table with all the resources present in the office, their salaries and their department\",\"Table with all the resources present in the office, their salaries and their department\",\"Table with all the departments and their average salaries\",\"Table with all the departments and their average salaries\"]\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940dfcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "- Column: order_date\n",
    "  - Description: Date when the order was placed\n",
    "  - Typical Values: \"2024-01-01\"\n",
    "  - Data Type: Date\n",
    "- Column: sales_amount\n",
    "  - Description: Total sale amount for the order\n",
    "  - Typical Values: 1000, 500\n",
    "  - Data Type: Float\n",
    "/Users/orion29/Documents/Projects/Langchain/lang graph/getting_started.ipynb/.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc886c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_schema = \"\"\n",
    "for i,j in column_description_table.groupby(\"table_name\"):\n",
    "    j = j.reset_index(drop=True)\n",
    "    table_schema+=\"Table name : \"+str(i)+\"\\n\"\n",
    "    table_schema+=\"Table description : \"+str(j[\"table_description\"].unique()[0])+\"\\n\\n\"\n",
    "    table_schema+=f\"Column descripitions of table {i}: \\n\"\n",
    "    for k in range(len(j)):\n",
    "        l = j.iloc[k]\n",
    "        table_schema+= \"Column name :\"+str(l[\"column_name\"])+\"\\n\"\n",
    "        table_schema+= \"Column description :\"+str(l[\"column_description\"])+\"\\n\"\n",
    "        table_schema+= \"Column description :\"+str(l[\"typical_values\"])+\"\\n\"\n",
    "    table_schema +=\"\\n\\n\"\n",
    "\n",
    "user_question = \"Which person has the highest salary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50a14be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4913b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"Which person has the highest salary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a059a5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a data expert who understands the structure of CSV files based on column descriptions.\n",
      "\n",
      "You will be given:\n",
      "- A user question.\n",
      "- A table schema, where each column has:\n",
      "    - Column Name\n",
      "    - Column Description\n",
      "    - Typical Values\n",
      "    - Data Type\n",
      "\n",
      "Your task:\n",
      "1. Read and deeply understand the user question.\n",
      "2. Think through the user needs and identify which columns are required. (Chain of Thought)\n",
      "3. Select the most relevant columns based on your reasoning.\n",
      "4. Identify and note any ambiguity if multiple interpretations are possible.\n",
      "\n",
      "---\n",
      "\n",
      "Here is the table schema:\n",
      "Table name : department_table\n",
      "Table description : Table with all the departments and their average salaries\n",
      "\n",
      "Column descripitions of table department_table: \n",
      "Column name :department\n",
      "Column description :name of the department in the organization\n",
      "Column description :electronics, communication, finance, hr\n",
      "Column name :average_salary\n",
      "Column description :Average salary provided to all the people in the department\n",
      "Column description :\n",
      "\n",
      "\n",
      "Table name : resource_table\n",
      "Table description : Table with all the resources present in the office, their salaries and their department\n",
      "\n",
      "Column descripitions of table resource_table: \n",
      "Column name :name\n",
      "Column description :Name of the person\n",
      "Column description :\n",
      "Column name :salary\n",
      "Column description :Annual salary given to the person in lakh per annum\n",
      "Column description :\n",
      "Column name :department\n",
      "Column description :name of the department where the person belongs to\n",
      "Column description :electronics, communication, finance, hr\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Here is the user question:\n",
      "Which person has the highest salary\n",
      "\n",
      "---\n",
      "\n",
      "Please follow this output format exactly:\n",
      "\n",
      "{\n",
      "    \"chain_of_thought\": \"<your reasoning process>\",\n",
      "    \"selected_columns\": [\n",
      "        {\n",
      "            \"table_name\": \"<table_name_1>\",\n",
      "            \"column_names\": [\"<column_name_1>\",\"<column_name_2>\",\"<column_name_1>\",\n",
      "        },\n",
      "        {\n",
      "            \"table_name\": \"<table_name_2>\",\n",
      "            \"column_names\": [\"<column_name_1>\",\"<column_name_2>\",\"<column_name_1>\",\n",
      "        },\n",
      "        ...\n",
      "    ],\n",
      "    \"ambiguity_notes\": \"<state ambiguity if any, otherwise null>\"\n",
      "}\n",
      "\n",
      "---\n",
      "Instructions:\n",
      "- In `chain_of_thought`, explain how you understood the query, what information you are looking for, and why.\n",
      "- Be selective: choose only columns truly needed to answer the user question.\n",
      "- If no ambiguity exists, set \"ambiguity_notes\" to null.\n",
      "- Keep the response in valid JSON format.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_question = \"Which person has the highest salary\"\n",
    "final_prompt = prompt_template.format(\n",
    "    table_schema=table_schema,\n",
    "    user_question=user_question)\n",
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab532a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "class LLMLoader:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def load_google_model_pro(self, temperature = 0):\n",
    "\n",
    "        load_dotenv()\n",
    "        os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "        model = ChatGoogleGenerativeAI(\n",
    "                model=\"gemini-1.5-pro-latest\",\n",
    "                temperature=temperature,\n",
    "                max_tokens=None,\n",
    "                timeout=None,\n",
    "                max_retries=2,\n",
    "                # other params...\n",
    "            )\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def load_google_model_flash2(self, temperature = 0):\n",
    "\n",
    "        load_dotenv()\n",
    "        os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "        model = ChatGoogleGenerativeAI(\n",
    "                model=\"models/gemini-2.0-flash\",\n",
    "                temperature=temperature,\n",
    "                max_tokens=None,\n",
    "                timeout=None,\n",
    "                max_retries=2,\n",
    "                # other params...\n",
    "            )\n",
    "\n",
    "        return model\n",
    "    \n",
    "\n",
    "\n",
    "model = LLMLoader()\n",
    "llm = model.load_google_model_flash2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68426135",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = LLMLoader()\n",
    "llm = model.load_google_model_flash2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f58a44c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a data expert who understands the structure of CSV files based on column descriptions.\n",
      "\n",
      "You will be given:\n",
      "- A user question.\n",
      "- A table schema, where each column has:\n",
      "    - Column Name\n",
      "    - Column Description\n",
      "    - Typical Values\n",
      "    - Data Type\n",
      "\n",
      "\n",
      "Your task:\n",
      "1. Read and deeply understand the user question.\n",
      "2. Think through the user needs and identify which columns are required. (Chain of Thought)\n",
      "3. Select the most relevant columns based on your reasoning.\n",
      "4. Identify and note any ambiguity if multiple interpretations are possible.\n",
      "5. Identify if multiple tables need to be joined, and suggest appropriate joins based on the context.\n",
      "\n",
      "Here is a brief explanation of Join Types:\n",
      "1. Inner Join: Return only matching records from both tables.\n",
      "2. Left Join: Return all records from the left table and matching records from the right table.\n",
      "3. Right Join: Return all records from the right table and matching records from the left table.\n",
      "4. Outer Join: Return all records from both tables, matching where possible, null where no match.\n",
      "\n",
      "---\n",
      "\n",
      "Here is the table schema:\n",
      "Table name : department_table\n",
      "Table description : Table with all the departments and their average salaries\n",
      "\n",
      "Column descripitions of table department_table: \n",
      "Column name :department\n",
      "Column description :name of the department in the organization\n",
      "Column description :electronics, communication, finance, hr\n",
      "Column name :average_salary\n",
      "Column description :Average salary provided to all the people in the department\n",
      "Column description :\n",
      "\n",
      "\n",
      "Table name : resource_table\n",
      "Table description : Table with all the resources present in the office, their salaries and their department\n",
      "\n",
      "Column descripitions of table resource_table: \n",
      "Column name :name\n",
      "Column description :Name of the person\n",
      "Column description :\n",
      "Column name :salary\n",
      "Column description :Annual salary given to the person in lakh per annum\n",
      "Column description :\n",
      "Column name :department\n",
      "Column description :name of the department where the person belongs to\n",
      "Column description :electronics, communication, finance, hr\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Here is the user question:\n",
      "Which person has the highest salary and how high is his salary comapred to department average\n",
      "\n",
      "---\n",
      "\n",
      "Please follow this output format exactly:\n",
      "\n",
      "{\n",
      "    \"chain_of_thought\": \"<your reasoning process>\",\n",
      "    \"selected_columns\": [\n",
      "        {\n",
      "            \"table_name\": \"<table_name_1>\",\n",
      "            \"column_names\": [\"<column_name_1>\",\"<column_name_2>\",\"<column_name_1>\",..]\n",
      "        },\n",
      "        {\n",
      "            \"table_name\": \"<table_name_2>\",\n",
      "            \"column_names\": [\"<column_name_1>\",\"<column_name_2>\",\"<column_name_1>\",..]\n",
      "        },\n",
      "        ...\n",
      "    ],\n",
      "    \"joins\": \n",
      "        {\n",
      "            \"left_table\": \"<table_name_1>\",\n",
      "            \"right_table\": \"<table_name_2>\",\n",
      "            \"left_column\": \"<column_name>\",\n",
      "            \"right_column\": \"<column_name>\",\n",
      "            \"join_type\": \"<inner | left | right | outer>\"\n",
      "        }\n",
      "    \"ambiguity_notes\": \"<state ambiguity if any, otherwise null>\"\n",
      "}\n",
      "\n",
      "---\n",
      "Instructions:\n",
      "- In `chain_of_thought`, explain how you understood the query, what information you are looking for, and why.\n",
      "- Be selective: choose only columns truly needed to answer the user question.\n",
      "- If no ambiguity exists, set \"ambiguity_notes\" to null.\n",
      "- Keep the response in valid JSON format.\n",
      "- In joins, define joins only if multiple tables must be combined.\n",
      "- Be specific in selecting join type based on context (default to inner if unsure).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_question = \"Which person has the highest salary and how high is his salary comapred to department average\"\n",
    "final_prompt = prompt_template.format(\n",
    "    table_schema=table_schema,\n",
    "    user_question=user_question)\n",
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "67ab1325",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = llm.invoke(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c749d0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n    \"chain_of_thought\": \"The user wants to find the person with the highest salary and then compare that salary to the average salary of the department they belong to. This requires information about individual salaries and department average salaries. Therefore, I need to select the \\'name\\' and \\'salary\\' columns from the \\'resource_table\\' to identify the person with the highest salary. I also need the \\'department\\' and \\'average_salary\\' columns from the \\'department_table\\' to find the average salary for that person\\'s department. Finally, I need to join these two tables on the \\'department\\' column to compare the individual\\'s salary with the department\\'s average salary.\",\\n    \"selected_columns\": [\\n        {\\n            \"table_name\": \"resource_table\",\\n            \"column_names\": [\\n                \"name\",\\n                \"salary\",\\n                \"department\"\\n            ]\\n        },\\n        {\\n            \"table_name\": \"department_table\",\\n            \"column_names\": [\\n                \"department\",\\n                \"average_salary\"\\n            ]\\n        }\\n    ],\\n    \"joins\": {\\n        \"left_table\": \"resource_table\",\\n        \"right_table\": \"department_table\",\\n        \"left_column\": \"department\",\\n        \"right_column\": \"department\",\\n        \"join_type\": \"inner\"\\n    },\\n    \"ambiguity_notes\": null\\n}\\n```'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cea52e",
   "metadata": {},
   "source": [
    "'```json\\n{\\n    \"chain_of_thought\": \"The user wants to find the person with the highest salary. This requires identifying each person\\'s name and their corresponding salary. Therefore, I need the \\'name\\' and \\'salary\\' columns from the \\'resource_table\\'.\",\\n    \"selected_columns\": [\\n        {\\n            \"column_name\": \"name\",\\n            \"reason\": \"This column contains the names of the people.\"\\n        },\\n        {\\n            \"column_name\": \"salary\",\\n            \"reason\": \"This column contains the salary of each person, which is needed to determine who has the highest salary.\"\\n        }\\n    ],\\n    \"ambiguity_notes\": null\\n}\\n```'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "46941f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_llm_content = x.content.strip(\"```json\\n\").strip(\"```\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bd483017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"chain_of_thought\": \"The user wants to find the person with the highest salary and then compare that salary to the average salary of the department they belong to. This requires information about individual salaries and department average salaries. Therefore, I need to select the \\'name\\' and \\'salary\\' columns from the \\'resource_table\\' to identify the person with the highest salary. I also need the \\'department\\' and \\'average_salary\\' columns from the \\'department_table\\' to find the average salary for that person\\'s department. Finally, I need to join these two tables on the \\'department\\' column to compare the individual\\'s salary with the department\\'s average salary.\",\\n    \"selected_columns\": [\\n        {\\n            \"table_name\": \"resource_table\",\\n            \"column_names\": [\\n                \"name\",\\n                \"salary\",\\n                \"department\"\\n            ]\\n        },\\n        {\\n            \"table_name\": \"department_table\",\\n            \"column_names\": [\\n                \"department\",\\n                \"average_salary\"\\n            ]\\n        }\\n    ],\\n    \"joins\": {\\n        \"left_table\": \"resource_table\",\\n        \"right_table\": \"department_table\",\\n        \"left_column\": \"department\",\\n        \"right_column\": \"department\",\\n        \"join_type\": \"inner\"\\n    },\\n    \"ambiguity_notes\": null\\n}'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_llm_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "455ee5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chain_of_thought': \"The user wants to find the person with the highest salary and then compare that salary to the average salary of the department they belong to. This requires information about individual salaries and department average salaries. Therefore, I need to select the 'name' and 'salary' columns from the 'resource_table' to identify the person with the highest salary. I also need the 'department' and 'average_salary' columns from the 'department_table' to find the average salary for that person's department. Finally, I need to join these two tables on the 'department' column to compare the individual's salary with the department's average salary.\",\n",
       " 'selected_columns': [{'table_name': 'resource_table',\n",
       "   'column_names': ['name', 'salary', 'department']},\n",
       "  {'table_name': 'department_table',\n",
       "   'column_names': ['department', 'average_salary']}],\n",
       " 'joins': {'left_table': 'resource_table',\n",
       "  'right_table': 'department_table',\n",
       "  'left_column': 'department',\n",
       "  'right_column': 'department',\n",
       "  'join_type': 'inner'},\n",
       " 'ambiguity_notes': None}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json.loads(cleaned_llm_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4fc919",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (4245919274.py, line 14)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[139]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m\"table_schema\": table_schema,\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"table_schema\", \"user_question\"],\n",
    "    template=prompt_template  # the prompt we built above\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "#output = chain.invoke({\n",
    " #   \"table_schema\": table_schema,\n",
    " #   \"user_question\": user_question\n",
    "#})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e7e50e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chain_of_thought': 'The user wants to find the person with the highest salary and then compare that salary to the average salary of the department they belong to. This requires information from both the `resource_table` (to find the person with the highest salary and their department) and the `department_table` (to find the average salary for that department). Therefore, I need to select the name, salary, and department from the `resource_table` and the department and average_salary from the `department_table`. A join is needed to combine these two tables on the department column.',\n",
       " 'selected_columns': [{'table_name': 'resource_table',\n",
       "   'column_names': ['name', 'salary', 'department']},\n",
       "  {'table_name': 'department_table',\n",
       "   'column_names': ['department', 'average_salary']}],\n",
       " 'joins': {'left_table': 'resource_table',\n",
       "  'right_table': 'department_table',\n",
       "  'left_column': 'department',\n",
       "  'right_column': 'department',\n",
       "  'join_type': 'inner'},\n",
       " 'ambiguity_notes': None}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "09e11a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chain_of_thought': 'The user wants to find the person with the highest salary and then compare that salary to the average salary of the department they belong to. This requires information from both the `resource_table` (to find the person with the highest salary and their department) and the `department_table` (to find the average salary for that department). Therefore, I need to select the name, salary, and department from the `resource_table` and the department and average_salary from the `department_table`. A join is needed to combine these two tables on the department column.',\n",
       " 'selected_columns': [{'table_name': 'resource_table',\n",
       "   'column_names': ['name', 'salary', 'department']},\n",
       "  {'table_name': 'department_table',\n",
       "   'column_names': ['department', 'average_salary']}],\n",
       " 'joins': {'left_table': 'resource_table',\n",
       "  'right_table': 'department_table',\n",
       "  'left_column': 'department',\n",
       "  'right_column': 'department',\n",
       "  'join_type': 'inner'},\n",
       " 'ambiguity_notes': None}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9b71ac48",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaseModel.__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[135]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/Query Bot/myenv/lib/python3.12/site-packages/langchain_core/load/serializable.py:130\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: BaseModel.__init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "parser(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0c31d30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='```json\\n{\\n    \"chain_of_thought\": \"The user wants to find the person with the highest salary and then compare that salary to the average salary of the department they belong to. This requires information about individual salaries and department average salaries. Therefore, I need to select the \\'name\\' and \\'salary\\' columns from the \\'resource_table\\' to identify the person with the highest salary. I also need the \\'department\\' and \\'average_salary\\' columns from the \\'department_table\\' to find the average salary for that person\\'s department. Finally, I need to join these two tables on the \\'department\\' column to compare the individual\\'s salary with the department\\'s average salary.\",\\n    \"selected_columns\": [\\n        {\\n            \"table_name\": \"resource_table\",\\n            \"column_names\": [\\n                \"name\",\\n                \"salary\",\\n                \"department\"\\n            ]\\n        },\\n        {\\n            \"table_name\": \"department_table\",\\n            \"column_names\": [\\n                \"department\",\\n                \"average_salary\"\\n            ]\\n        }\\n    ],\\n    \"joins\": {\\n        \"left_table\": \"resource_table\",\\n        \"right_table\": \"department_table\",\\n        \"left_column\": \"department\",\\n        \"right_column\": \"department\",\\n        \"join_type\": \"inner\"\\n    },\\n    \"ambiguity_notes\": null\\n}\\n```', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-4ff107ca-ee5f-4945-8681-b0001c090294-0', usage_metadata={'input_tokens': 810, 'output_tokens': 318, 'total_tokens': 1128, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9764fd84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebac7cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'department_table': '../data/department_table.csv',\n",
       " 'resource_table': '../data/resource_table.csv'}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7d1da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "with open('../prompt/code_generation.txt', 'r') as f:\n",
    "    code_prompt_template = f.read()\n",
    "table_path = {\"department_table\":\"../data/department_table.csv\",\"resource_table\":\"../data/resource_table.csv\"}\n",
    "table_path\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables=[\"structured_json_output\", \"user_question\",\"table_path\",\"old_code\",\"traceback_error\"],\n",
    "    template=code_prompt_template  # the prompt we built above\n",
    ")\n",
    "\n",
    "chain = prompt2 | llm | parser\n",
    "\n",
    "output2 = chain.invoke({\n",
    "   \"structured_json_output\": output,\n",
    "   \"user_question\": user_question,\n",
    "   \"table_path\":table_path,\n",
    "   \"old_code\": \"\",\n",
    "   \"traceback_error\":\"\"\n",
    "   \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb8b6e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "261a3688",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_vars={}\n",
    "exec(output2[\"python_code\"], globals(), local_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "1f707eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pd', 'json', 'traceback', 'department_table_path', 'resource_table_path', 'department_table', 'resource_table', 'merged_df', 'highest_salary_person', 'salary_difference', 'result', 'final_output'])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_vars.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b115a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df = pd.DataFrame({'a': [1,2,3]})\n",
      "final_output = {\n",
      "    \"output\": df.to_dict(),\n",
      "    \"traceback_error\": None\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute\n",
    "if final_output[\"traceback_error\"] is None and final_output[\"output\"] is not None:\n",
    "    local_vars = {\n",
    "        \"pd\": pd,\n",
    "    }\n",
    "    exec(final_output[\"output\"][\"your_code_key\"], globals(), local_vars)\n",
    "\n",
    "    print(local_vars[\"final_output\"])\n",
    "else:\n",
    "    print(final_output[\"traceback_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05948171",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_vars = {}\n",
    "exec(final_output[\"output\"][\"your_code_key\"],globals(),local_vars)\n",
    "python_output = local_vars['final_output'][\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "e420f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_output = local_vars['final_output'][\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c82a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8709b457",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = llm.invoke(output_prompt )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "19e8bb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The person with the highest salary is Laura Rodriguez 0486, with a salary of $30.0. This is $13.53 higher than the department average salary of $16.47.'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c288c44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user wants to find the person with the highest salary and then compare that salary to the average salary of the department they belong to. This requires information from both the `resource_table` (to find the person with the highest salary and their department) and the `department_table` (to find the average salary for that department). Therefore, I need to select the name, salary, and department from the `resource_table` and the department and average_salary from the `department_table`. A join is needed to combine these two tables on the department column.\n"
     ]
    }
   ],
   "source": [
    "print(output['chain_of_thought'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "fc7857fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert AI assistant that converts structured JSON outputs into clear, friendly, human-readable answers for end users.\n",
      "\n",
      "You will be given:\n",
      "- A user question.\n",
      "- A structured JSON output generated from data analysis or computation.\n",
      "\n",
      "Your task:\n",
      "1. Understand the user's original question.\n",
      "2. Read the JSON output carefully.\n",
      "3. Create a well-written, natural language answer that:\n",
      "  a. Directly addresses the user's question.\n",
      "  b. Highlights important results in a clean, easy-to-read format.\n",
      "  c. Is brief, clear, and helpful.\n",
      "4. Avoid repeating the user's question unless necessary.\n",
      "5. If the JSON output is empty or missing important fields, politely tell the user that no answer could be generated.\n",
      "\n",
      "Input format:\n",
      "\n",
      "Here is the user question:\n",
      "{user_question}\n",
      "\n",
      "Here is the json geenrated by the python code\n",
      "{output}\n",
      "\n",
      "Important instructions:\n",
      "1. Always prioritize clarity and conciseness.\n",
      "2. If multiple fields are present, summarize them in a bulleted list or short paragraph.\n",
      "3. If any numbers, differences, percentages are present, explain them simply.\n",
      "4. Never dump raw JSON or raw code to the user.\n",
      "5. If the output includes a person, item, or metric of interest, highlight it.\n",
      "\n",
      "Few Shot Examples:\n",
      "\n",
      "If the JSON says {{ \"highest_salary\": 120000, \"name\": \"John Doe\" }}, output:\n",
      "\"John Doe has the highest salary of $120,000.\"\n",
      "\n",
      "If the JSON says {{}}, output:\n",
      "\"Sorry, no relevant information could be found to answer your question.\"\n",
      "\n",
      "If the JSON has fields like \"average_department_salary\", explain it naturally:\n",
      "\"The average salary in the department is $85,000.\" \n"
     ]
    }
   ],
   "source": [
    "with open('../prompt/pretty_print.txt', 'r') as f:\n",
    "    pretty_print_template = f.read()\n",
    "print(pretty_print_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcbf037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "with open('../prompt/pretty_print.txt', 'r') as f:\n",
    "    pretty_print_template = f.read()\n",
    "print(pretty_print_template)\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables=[\"user_question\",\"output\"],\n",
    "    template=pretty_print_template # the prompt we built above\n",
    ")\n",
    "\n",
    "chain = prompt2 | llm\n",
    "\n",
    "output3 = chain.invoke({\n",
    "   \"user_question\":user_question,\n",
    "   \"output\":python_output\n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0b963f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "class State(TypedDict):\n",
    "\n",
    "\n",
    "    user_input : str             # The raw query user sends\n",
    "    optimized_prompt : str       # After prompt cleaning\n",
    "    context : dict                  # Any past conversation context\n",
    "    schema : {}                 # Selected DataFrame schema\n",
    "    ambiguity_flags : bool         # If multiple schema/columns matched\n",
    "    pandas_code : str             # Generated code\n",
    "    execution_result : str        # Output after code is run\n",
    "    memory : list                    # Long-term or session memory\n",
    "    agent_status: dict  \n",
    "    prompt_path : str\n",
    "    data_path : str\n",
    "    column_description_table : str\n",
    "    traceback_error : str\n",
    "    chain_of_thought : {}\n",
    "    bot_output : str\n",
    "    code_execution_limit : int\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43695a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "class LLMLoader:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def load_google_model_pro(self, temperature = 0):\n",
    "\n",
    "        load_dotenv()\n",
    "        os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "        model = ChatGoogleGenerativeAI(\n",
    "                model=\"gemini-1.5-pro-latest\",\n",
    "                temperature=temperature,\n",
    "                max_tokens=None,\n",
    "                timeout=None,\n",
    "                max_retries=2,\n",
    "                # other params...\n",
    "            )\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def load_google_model_flash2(self, temperature = 0):\n",
    "\n",
    "        load_dotenv()\n",
    "        os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "        model = ChatGoogleGenerativeAI(\n",
    "                model=\"models/gemini-2.0-flash\",\n",
    "                temperature=temperature,\n",
    "                max_tokens=None,\n",
    "                timeout=None,\n",
    "                max_retries=2,\n",
    "                # other params...\n",
    "            )\n",
    "\n",
    "        return model\n",
    "    \n",
    "\n",
    "\n",
    "model = LLMLoader()\n",
    "llm = model.load_google_model_flash2()\n",
    "\n",
    "from typing import TypedDict\n",
    "class State(TypedDict):\n",
    "\n",
    "\n",
    "    user_input : str             # The raw query user sends\n",
    "    optimized_prompt : str       # After prompt cleaning\n",
    "    context : dict                  # Any past conversation context\n",
    "    schema : {}                 # Selected DataFrame schema\n",
    "    ambiguity_flags : bool         # If multiple schema/columns matched\n",
    "    pandas_code : str             # Generated code\n",
    "    execution_result : str        # Output after code is run\n",
    "    memory : list                    # Long-term or session memory\n",
    "    agent_status: dict  \n",
    "    prompt_path : str\n",
    "    data_path : str\n",
    "    column_description_table : str\n",
    "    traceback_error : str\n",
    "    chain_of_thought : {}\n",
    "    bot_output : str\n",
    "    code_execution_limit : int\n",
    "          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f6bdcee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "def create_schema_selection_agent(llm):\n",
    "    def schema_selection_agent(state : State )->State:\n",
    "\n",
    "        user_question = state[\"user_input\"]\n",
    "        column_description_table_path = state[\"column_description_table\"]\n",
    "        column_description_table = pd.read_csv(column_description_table_path)\n",
    "\n",
    "        prompt_path = state[\"prompt_path\"] + \"schema_selection.txt\"\n",
    "\n",
    "        with open(prompt_path, 'r') as f:\n",
    "            schema_selection_template = f.read()\n",
    "\n",
    "        table_schema = \"\"\n",
    "        for i,j in column_description_table.groupby(\"table_name\"):\n",
    "            j = j.reset_index(drop=True)\n",
    "            table_schema+=\"Table name : \"+str(i)+\"\\n\"\n",
    "            table_schema+=\"Table description : \"+str(j[\"table_description\"].unique()[0])+\"\\n\\n\"\n",
    "            table_schema+=f\"Column descripitions of table {i}: \\n\"\n",
    "            for k in range(len(j)):\n",
    "                l = j.iloc[k]\n",
    "                table_schema+= \"Column name :\"+str(l[\"column_name\"])+\"\\n\"\n",
    "                table_schema+= \"Column description :\"+str(l[\"column_description\"])+\"\\n\"\n",
    "                table_schema+= \"Column description :\"+str(l[\"typical_values\"])+\"\\n\"\n",
    "            table_schema +=\"\\n\\n\"\n",
    "\n",
    "        \n",
    "        schema_selection_prompt = PromptTemplate(\n",
    "                            input_variables=[\"user_question\",\"table_schema\"],\n",
    "                            template=schema_selection_template )\n",
    "        \n",
    "        parser = JsonOutputParser()\n",
    "\n",
    "        \n",
    "        schema_chain = schema_selection_prompt | llm | parser\n",
    "\n",
    "        schema_json = schema_chain.invoke({\n",
    "                \"table_schema\":table_schema,\n",
    "                \"user_question\":user_question})\n",
    "        \n",
    "        state[\"schema\"] = schema_json\n",
    "\n",
    "        state[\"chain_of_thought\"][\"Schema selection\"]  = schema_json['chain_of_thought']\n",
    "\n",
    "        print(schema_json)\n",
    "\n",
    "\n",
    "    #    schema = \"\"\n",
    "    #    for one_table in output[\"schema\"][\"selected_columns\"][:1]:\n",
    "    #        i = one_table[\"table_name\"]\n",
    "    #        j = column_description_table[column_description_table[\"table_name\"] == i].reset_index(drop=True)\n",
    "    #        schema+=\"Table name : \"+str(i)+\"\\n\"\n",
    "    #        schema+=\"Table description : \"+str(j[\"table_description\"].unique()[0])+\"\\n\\n\"\n",
    "    #        schema+=f\"Description of selected columns {i}: \\n\"\n",
    "    #        for k in range(len(j)):\n",
    "    #            l = j.iloc[k]\n",
    "    #            if l[\"column_name\"] in one_table[\"column_names\"]:\n",
    "    #                schema+= \"Column name :\"+str(l[\"column_name\"])+\"\\n\"\n",
    "    #                schema+= \"Column description :\"+str(l[\"column_description\"])+\"\\n\"\n",
    "    #                schema+= \"Column description :\"+str(l[\"typical_values\"])+\"\\n\"\n",
    "    #        schema +=\"\\n\\n\"\n",
    "\n",
    "        return state\n",
    "    return schema_selection_agent   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "72d8ba40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For table a use path b\n",
      "For table c use path c\n",
      "\n"
     ]
    }
   ],
   "source": [
    "z = {\"a\":\"b\",\"c\":\"c\"}\n",
    "l = \"\"\n",
    "for i in z.keys():\n",
    "    l+=\"For table \"+i+\" use path \"+z[i]+\"\\n\"\n",
    "\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0e8cb4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c88465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "def create_code_generation_agent(llm):\n",
    "    def code_generation_agent(state : State) -> State:\n",
    "        \n",
    "        user_question = state[\"user_input\"]\n",
    "        output = state[\"schema\"]\n",
    "        data_path = state[\"data_path\"]\n",
    "\n",
    "        table_path_dict = {str(i[\"table_name\"]):data_path+str(i[\"table_name\"])+\".csv\" for i in output[\"selected_columns\"]}\n",
    "\n",
    "        table_path = \"\"\n",
    "        for i in table_path_dict.keys():\n",
    "            table_path+=\"For table \"+i+\" use path \"+table_path_dict[i]+\"\\n\"\n",
    "        \n",
    "\n",
    "        prompt_path = state[\"prompt_path\"] + \"code_generation.txt\"\n",
    "\n",
    "        with open(prompt_path, 'r') as f:\n",
    "            code_generation_template = f.read()\n",
    "\n",
    "\n",
    "        code_generation_prompt = PromptTemplate(input_variables=[\"structured_json_output\", \"user_question\",\"table_path\",\"old_code\",\"traceback_error\"],\n",
    "                                                template=code_generation_template  )\n",
    "        \n",
    "        parser = JsonOutputParser()\n",
    "\n",
    "        code_chain = code_generation_prompt | llm | parser\n",
    "\n",
    "        output = code_chain.invoke({\n",
    "                            \"structured_json_output\": output,\n",
    "                            \"user_question\": user_question,\n",
    "                            \"table_path\":table_path,\n",
    "                            \"old_code\": state[\"pandas_code\"],\n",
    "                            \"traceback_error\":state[\"traceback_error\"]\n",
    "                            \n",
    "                            })\n",
    "        \n",
    "        state[\"chain_of_thought\"][\"Code Generation\"] = output[\"chain_of_thought\"]\n",
    "        state[\"pandas_code\"] = output['python_code']\n",
    "        state[\"code_execution_limit\"] -= 1\n",
    "        print(output)\n",
    "        return state\n",
    "    return code_generation_agent   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1caa0885",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def code_execution_agent(state:State)->State:\n",
    "    \n",
    "    local_vars = {}\n",
    "    pandas_code = state[\"pandas_code\" ]\n",
    "    exec(pandas_code ,globals(),local_vars)\n",
    "    python_output = local_vars['final_output'][\"output\"]\n",
    "    error = local_vars['final_output']['traceback_error']\n",
    "    \n",
    "\n",
    "    state[\"execution_result\"] = python_output\n",
    "    state[\"traceback_error\"] = error\n",
    "\n",
    "    print(local_vars['final_output'])\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9660c193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretty_print_agent(llm):\n",
    "    def pretty_print_agent(state:State)->State:\n",
    "\n",
    "        user_question = state[\"user_input\"]\n",
    "        python_output = state[\"execution_result\"]\n",
    "\n",
    "        prompt_path = state[\"prompt_path\"] + \"pretty_print.txt\"\n",
    "\n",
    "        with open(prompt_path, 'r') as f:\n",
    "            pretty_print_template = f.read()\n",
    "\n",
    "        pretty_print_prompt = PromptTemplate(\n",
    "            input_variables=[\"user_question\",\"output\"],\n",
    "            template=pretty_print_template )\n",
    "\n",
    "\n",
    "        chain = pretty_print_prompt | llm\n",
    "\n",
    "        output = chain.invoke({\n",
    "        \"user_question\":user_question,\n",
    "        \"output\":python_output })\n",
    "\n",
    "        state[\"bot_output\"] = output.content\n",
    "        print(output.content)\n",
    "\n",
    "        return state\n",
    "    return pretty_print_agent\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cf90c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1dafd9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START,END,StateGraph\n",
    "\n",
    "def check_code_status(state:State):\n",
    "\n",
    "    pandas_code = state[\"pandas_code\"] \n",
    "    if pandas_code is None:\n",
    "        return \"pretty_print_agent\"\n",
    "    else:\n",
    "        return \"code_execution_agent\"\n",
    "    \n",
    "def check_execution_status(state:State)->str:\n",
    "\n",
    "    execution_result = state[\"execution_result\"] \n",
    "    \n",
    "    state[\"code_execution_limit\"]\n",
    "    code_execution_limit = state[\"code_execution_limit\" ]\n",
    "\n",
    "    if execution_result  :\n",
    "        return \"pretty_print_agent\"\n",
    "    elif code_execution_limit == 0:\n",
    "        return \"pretty_print_agent\"\n",
    "    else:\n",
    "        return \"code_generation_agent\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "builder  = StateGraph(State)\n",
    "\n",
    "schema_selection_agent= create_schema_selection_agent(llm)\n",
    "code_generation_agent = create_code_generation_agent(llm)\n",
    "pretty_print_agent = create_pretty_print_agent(llm)\n",
    " \n",
    "builder.add_node(schema_selection_agent,\"schema_selection_agent\")\n",
    "builder.add_node(code_generation_agent,\"code_generation_agent\")\n",
    "builder.add_node(code_execution_agent,\"code_execution_agent\")\n",
    "builder.add_node(pretty_print_agent,\"pretty_print_agent\")\n",
    "\n",
    "\n",
    "builder.add_edge(START,\"schema_selection_agent\")\n",
    "builder.add_edge(\"schema_selection_agent\",\"code_generation_agent\")\n",
    "#builder.add_edge(\"code_generation_agent\",\"code_execution_agent\")\n",
    "builder.add_conditional_edges(\"code_generation_agent\",check_code_status)\n",
    "builder.add_conditional_edges(\"code_execution_agent\",check_execution_status)\n",
    "#builder.add_edge(\"code_execution_agent\",\"pretty_print_agent\")\n",
    "builder.add_edge(\"pretty_print_agent\",END)\n",
    "\n",
    "graph1 = builder.compile()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "34b93cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "display(Image(graph1.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748b6603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ba415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"Which person has the lowest salary and how low is his salary compared to department average\"\n",
    "state = {\n",
    "    \"user_input\":user_question,  \n",
    "    \"agent_status\":{\"schema_selection_node\":True},\n",
    "    \"prompt_path\" : \"../prompt/\",\n",
    "    \"data_path\" : \"../data/\",\n",
    "    \"column_description_table\"  : \"../data/column_description_table.csv\",\n",
    "    \"pandas_code\" :\"\",\n",
    "    \"traceback_error\" : \"\",\n",
    "    \"chain_of_thought\" : {},\n",
    "    \"code_execution_limit\" : 3,\n",
    "    \"execution_result\"  : \"\"\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "output = graph1.invoke(state)\n",
    "print(output[\"bot_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "219d3614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chain_of_thought': \"The user wants to find the person with the lowest salary and then compare that salary to the average salary of the department they belong to. This requires information about each person's salary and department, as well as the average salary for each department. Therefore, I need to access both the `resource_table` and the `department_table`. From the `resource_table`, I need the person's name, salary, and department. From the `department_table`, I need the department name and average salary. I will then join these tables on the department name to compare the individual's salary to the department average.\", 'selected_columns': [{'table_name': 'resource_table', 'column_names': ['name', 'salary', 'department']}, {'table_name': 'department_table', 'column_names': ['department', 'average_salary']}], 'joins': {'left_table': 'resource_table', 'right_table': 'department_table', 'left_column': 'department', 'right_column': 'department', 'join_type': 'inner'}, 'ambiguity_notes': None}\n",
      "{'chain_of_thought': \"The user wants to find the person with the lowest salary and compare it to their department's average salary. The provided JSON contains all the necessary information: the tables to use (`resource_table` and `department_table`), the columns to select from each table, and the join condition. I will load the data, select the relevant columns, perform the join, find the person with the minimum salary, and then calculate the difference between their salary and their department's average salary. The result will be a dictionary containing the person's name and the salary difference.\", 'python_code': 'import pandas as pd\\nimport json\\nimport traceback\\n\\ntry:\\n    # Load the dataframes (assuming they are already loaded)\\n    # resource_table = pd.read_csv(\"../data/resource_table.csv\")\\n    # department_table = pd.read_csv(\"../data/department_table.csv\")\\n\\n    # Select the necessary columns\\n    resource_table = resource_table[[\\'name\\', \\'salary\\', \\'department\\']]\\n    department_table = department_table[[\\'department\\', \\'average_salary\\']]\\n\\n    # Perform the join\\n    merged_table = pd.merge(resource_table, department_table, how=\\'inner\\', left_on=\\'department\\', right_on=\\'department\\')\\n\\n    # Find the person with the lowest salary\\n    min_salary_person = merged_table.loc[merged_table[\\'salary\\'] == merged_table[\\'salary\\'].min()]\\n\\n    # Calculate the difference between the person\\'s salary and the department average\\n    salary_difference = min_salary_person[\\'salary\\'].values[0] - min_salary_person[\\'average_salary\\'].values[0]\\n\\n    # Get the name of the person\\n    person_name = min_salary_person[\\'name\\'].values[0]\\n\\n    # Store the result\\n    result = {\\n        \\'person_name\\': person_name,\\n        \\'salary_difference\\': salary_difference\\n    }\\n\\n    final_output = {\\n        \\'output\\': result,\\n        \\'traceback_error\\': None\\n    }\\n\\nexcept Exception as e:\\n    final_output = {\\n        \\'output\\': {},\\n        \\'traceback_error\\': traceback.format_exc()\\n    }\\n'}\n",
      "{'output': {}, 'traceback_error': 'Traceback (most recent call last):\\n  File \"<string>\", line 11, in <module>\\nNameError: name \\'resource_table\\' is not defined\\n'}\n",
      "{'chain_of_thought': \"The user wants to find the person with the lowest salary and compare it to their department's average salary. The traceback indicates a NameError because the dataframes `resource_table` and `department_table` were not loaded before being used. I will load the dataframes from the specified paths, select the necessary columns, perform the join, find the person with the minimum salary, calculate the difference between their salary and their department's average salary, and then return the person's name and the salary difference.\", 'python_code': 'import pandas as pd\\nimport json\\nimport traceback\\n\\ntry:\\n    # Load the dataframes\\n    resource_table = pd.read_csv(\"../data/resource_table.csv\")\\n    department_table = pd.read_csv(\"../data/department_table.csv\")\\n\\n    # Select the necessary columns\\n    resource_table = resource_table[[\\'name\\', \\'salary\\', \\'department\\']]\\n    department_table = department_table[[\\'department\\', \\'average_salary\\']]\\n\\n    # Perform the join\\n    merged_table = pd.merge(resource_table, department_table, how=\\'inner\\', left_on=\\'department\\', right_on=\\'department\\')\\n\\n    # Find the person with the lowest salary\\n    min_salary_person = merged_table.loc[merged_table[\\'salary\\'] == merged_table[\\'salary\\'].min()]\\n\\n    # Calculate the difference between the person\\'s salary and the department average\\n    salary_difference = min_salary_person[\\'salary\\'].values[0] - min_salary_person[\\'average_salary\\'].values[0]\\n\\n    # Get the name of the person\\n    person_name = min_salary_person[\\'name\\'].values[0]\\n\\n    # Store the result\\n    result = {\\n        \\'person_name\\': person_name,\\n        \\'salary_difference\\': salary_difference\\n    }\\n\\n    final_output = {\\n        \\'output\\': result,\\n        \\'traceback_error\\': None\\n    }\\n\\nexcept Exception as e:\\n    final_output = {\\n        \\'output\\': {},\\n        \\'traceback_error\\': traceback.format_exc()\\n    }\\n'}\n",
      "{'output': {'person_name': 'Andrew Thomas 0579', 'salary_difference': np.float64(-12.402573529411764)}, 'traceback_error': None}\n",
      "The person with the lowest salary compared to their department average is **Andrew Thomas 0579**. His salary is $12.40 lower than the average salary of his department.\n",
      "The person with the lowest salary compared to their department average is **Andrew Thomas 0579**. His salary is $12.40 lower than the average salary of his department.\n"
     ]
    }
   ],
   "source": [
    "output = graph1.invoke(state)\n",
    "print(output[\"bot_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d8a2f9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_input': 'Which person has the highest salary and how high is his salary compared to department average',\n",
       " 'schema': {'chain_of_thought': \"The user wants to find the person with the highest salary and then compare that salary to the average salary of the department they belong to. To achieve this, I need to find the person with the maximum salary from the `resource_table`. Then, I need to find the average salary of that person's department from the `department_table`. Finally, I need to compare these two values. Therefore, I need to select the name, salary, and department from the `resource_table` and the department and average_salary from the `department_table`. A join is required to combine the information from both tables based on the department.\",\n",
       "  'selected_columns': [{'table_name': 'resource_table',\n",
       "    'column_names': ['name', 'salary', 'department']},\n",
       "   {'table_name': 'department_table',\n",
       "    'column_names': ['department', 'average_salary']}],\n",
       "  'joins': {'left_table': 'resource_table',\n",
       "   'right_table': 'department_table',\n",
       "   'left_column': 'department',\n",
       "   'right_column': 'department',\n",
       "   'join_type': 'inner'},\n",
       "  'ambiguity_notes': None},\n",
       " 'pandas_code': 'import pandas as pd\\nimport json\\nimport traceback\\n\\ntry:\\n    # --- Load necessary dataframes ---    \\n    resource_table = pd.read_csv(\"../data/resource_table.csv\")\\n    department_table = pd.read_csv(\"../data/department_table.csv\")\\n\\n    # --- Select only necessary columns ---\\n    resource_table = resource_table[[\\'name\\', \\'salary\\', \\'department\\']]\\n    department_table = department_table[[\\'department\\', \\'average_salary\\']]\\n\\n    # --- Perform joins as needed ---\\n    merged_df = pd.merge(\\n        resource_table,\\n        department_table,\\n        how=\"inner\",\\n        left_on=\"department\",\\n        right_on=\"department\"\\n    )\\n\\n    # --- Find the person with the highest salary ---\\n    highest_salary_person = merged_df.loc[merged_df[\\'salary\\'].idxmax()]\\n\\n    # --- Calculate the difference between the highest salary and the department average salary ---\\n    salary_difference = highest_salary_person[\\'salary\\'] - highest_salary_person[\\'average_salary\\']\\n\\n    # --- Prepare the final output ---\\n    result = {\\n        \"highest_salary_person\": highest_salary_person[\\'name\\'],\\n        \"highest_salary\": highest_salary_person[\\'salary\\'],\\n        \"department\": highest_salary_person[\\'department\\'],\\n        \"department_average_salary\": highest_salary_person[\\'average_salary\\'],\\n        \"salary_difference\": salary_difference\\n    }\\n\\n    final_output = {\\n        \"output\": result,\\n        \"traceback_error\": None\\n    }\\n\\nexcept Exception as e:\\n    final_output = {\\n        \"output\": {},\\n        \"traceback_error\": traceback.format_exc()\\n    }\\n',\n",
       " 'execution_result': {'highest_salary_person': 'Laura Rodriguez 0486',\n",
       "  'highest_salary': np.float64(30.0),\n",
       "  'department': 'hr',\n",
       "  'department_average_salary': np.float64(16.465126050420167),\n",
       "  'salary_difference': np.float64(13.534873949579833)},\n",
       " 'agent_status': {'schema_selection_node': True},\n",
       " 'prompt_path': '../prompt/',\n",
       " 'data_path': '../data/',\n",
       " 'column_description_table': '../data/column_description_table.csv',\n",
       " 'traceback_error': None,\n",
       " 'chain_of_thought': {'Schema selection': \"The user wants to find the person with the highest salary and then compare that salary to the average salary of the department they belong to. To achieve this, I need to find the person with the maximum salary from the `resource_table`. Then, I need to find the average salary of that person's department from the `department_table`. Finally, I need to compare these two values. Therefore, I need to select the name, salary, and department from the `resource_table` and the department and average_salary from the `department_table`. A join is required to combine the information from both tables based on the department.\",\n",
       "  'Code Generation': \"The user is asking for the person with the highest salary and how their salary compares to the average salary of their department. The structured JSON provides the necessary tables, columns, and join information to answer this question. I will first read the data from the CSV files into Pandas DataFrames. Then, I will select the required columns from each DataFrame. Next, I will perform an inner join between the `resource_table` and `department_table` on the 'department' column. After the join, I will find the person with the highest salary. Finally, I will calculate the difference between the highest salary and the average salary of that person's department and return the result.\"},\n",
       " 'bot_output': 'The person with the highest salary is **Laura Rodriguez 0486**, with a salary of $30.0. This is $13.53 higher than the average salary in the hr department, which is $16.47.',\n",
       " 'code_execution_limit': 2}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "97902946",
   "metadata": {},
   "outputs": [],
   "source": [
    "statusa = pretty_print_agent(statez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5a2ffafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The person with the highest salary is **Laura Rodriguez 0486**, who earns $30.0. This is $13.53 higher than the department average salary of $16.47.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statusa[\"bot_output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "a9a0b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = \"\"\n",
    "for one_table in output[\"schema\"][\"selected_columns\"][:1]:\n",
    "    i = one_table[\"table_name\"]\n",
    "    j = column_description_table[column_description_table[\"table_name\"] == i].reset_index(drop=True)\n",
    "    schema+=\"Table name : \"+str(i)+\"\\n\"\n",
    "    schema+=\"Table description : \"+str(j[\"table_description\"].unique()[0])+\"\\n\\n\"\n",
    "    schema+=f\"Description of selected columns {i}: \\n\"\n",
    "    for k in range(len(j)):\n",
    "        l = j.iloc[k]\n",
    "        if l[\"column_name\"] in one_table[\"column_names\"]:\n",
    "            schema+= \"Column name :\"+str(l[\"column_name\"])+\"\\n\"\n",
    "            schema+= \"Column description :\"+str(l[\"column_description\"])+\"\\n\"\n",
    "            schema+= \"Column description :\"+str(l[\"typical_values\"])+\"\\n\"\n",
    "    schema +=\"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b691fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'agent'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[282]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magent\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magent1\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m helper\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'agent'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "91b5da18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['chain_of_thought', 'python_code'])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9af0b0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "import pandas as pd\n",
    "from langgraph.graph import START,END,StateGraph\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from typing import TypedDict,Literal\n",
    "\n",
    "class LLMLoader:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def load_google_model_pro(self, temperature = 0):\n",
    "\n",
    "        load_dotenv()\n",
    "        os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "        model = ChatGoogleGenerativeAI(\n",
    "                model=\"gemini-1.5-pro-latest\",\n",
    "                temperature=temperature,\n",
    "                max_tokens=None,\n",
    "                timeout=None,\n",
    "                max_retries=2,\n",
    "                # other params...\n",
    "            )\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def load_google_model_flash2(self, temperature = 0):\n",
    "\n",
    "        load_dotenv()\n",
    "        os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "        model = ChatGoogleGenerativeAI(\n",
    "                model=\"models/gemini-2.0-flash\",\n",
    "                temperature=temperature,\n",
    "                max_tokens=None,\n",
    "                timeout=None,\n",
    "                max_retries=2,\n",
    "                # other params...\n",
    "            )\n",
    "\n",
    "        return model\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "\n",
    "\n",
    "    user_input : str            \n",
    "    optimized_prompt : str       \n",
    "    context : dict                 \n",
    "    schema : {}                 \n",
    "    ambiguity_flags : bool         \n",
    "    pandas_code : str             \n",
    "    execution_result : str        \n",
    "    memory : list                    \n",
    "    agent_status: dict  \n",
    "    prompt_path : str\n",
    "    data_path : str\n",
    "    column_description_table : str\n",
    "    traceback_error : str\n",
    "    chain_of_thought : {}\n",
    "    bot_output : str\n",
    "    code_execution_limit : int\n",
    "          \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_schema_selection_agent(llm):\n",
    "    def schema_selection_agent(state : State )->State:\n",
    "\n",
    "        user_question = state[\"user_input\"]\n",
    "        column_description_table_path = state[\"column_description_table\"]\n",
    "        column_description_table = pd.read_csv(column_description_table_path)\n",
    "\n",
    "        prompt_path = state[\"prompt_path\"] + \"schema_selection.txt\"\n",
    "\n",
    "        with open(prompt_path, 'r') as f:\n",
    "            schema_selection_template = f.read()\n",
    "\n",
    "        table_schema = \"\"\n",
    "        for i,j in column_description_table.groupby(\"table_name\"):\n",
    "            j = j.reset_index(drop=True)\n",
    "            table_schema+=\"Table name : \"+str(i)+\"\\n\"\n",
    "            table_schema+=\"Table description : \"+str(j[\"table_description\"].unique()[0])+\"\\n\\n\"\n",
    "            table_schema+=f\"Column descripitions of table {i}: \\n\"\n",
    "            for k in range(len(j)):\n",
    "                l = j.iloc[k]\n",
    "                table_schema+= \"Column name :\"+str(l[\"column_name\"])+\"\\n\"\n",
    "                table_schema+= \"Column description :\"+str(l[\"column_description\"])+\"\\n\"\n",
    "                table_schema+= \"Column description :\"+str(l[\"typical_values\"])+\"\\n\"\n",
    "            table_schema +=\"\\n\\n\"\n",
    "\n",
    "        \n",
    "        schema_selection_prompt = PromptTemplate(\n",
    "                            input_variables=[\"user_question\",\"table_schema\"],\n",
    "                            template=schema_selection_template )\n",
    "        \n",
    "        parser = JsonOutputParser()\n",
    "\n",
    "        \n",
    "        schema_chain = schema_selection_prompt | llm | parser\n",
    "\n",
    "        schema_json = schema_chain.invoke({\n",
    "                \"table_schema\":table_schema,\n",
    "                \"user_question\":user_question})\n",
    "        \n",
    "        state[\"schema\"] = schema_json\n",
    "\n",
    "        state[\"chain_of_thought\"][\"Schema selection\"]  = schema_json['chain_of_thought']\n",
    "\n",
    "        print(schema_json)\n",
    "\n",
    "\n",
    "    #    schema = \"\"\n",
    "    #    for one_table in output[\"schema\"][\"selected_columns\"][:1]:\n",
    "    #        i = one_table[\"table_name\"]\n",
    "    #        j = column_description_table[column_description_table[\"table_name\"] == i].reset_index(drop=True)\n",
    "    #        schema+=\"Table name : \"+str(i)+\"\\n\"\n",
    "    #        schema+=\"Table description : \"+str(j[\"table_description\"].unique()[0])+\"\\n\\n\"\n",
    "    #        schema+=f\"Description of selected columns {i}: \\n\"\n",
    "    #        for k in range(len(j)):\n",
    "    #            l = j.iloc[k]\n",
    "    #            if l[\"column_name\"] in one_table[\"column_names\"]:\n",
    "    #                schema+= \"Column name :\"+str(l[\"column_name\"])+\"\\n\"\n",
    "    #                schema+= \"Column description :\"+str(l[\"column_description\"])+\"\\n\"\n",
    "    #                schema+= \"Column description :\"+str(l[\"typical_values\"])+\"\\n\"\n",
    "    #        schema +=\"\\n\\n\"\n",
    "\n",
    "        return state\n",
    "    return schema_selection_agent  \n",
    "\n",
    "\n",
    "def create_code_generation_agent(llm):\n",
    "    def code_generation_agent(state : State) -> State:\n",
    "        \n",
    "        user_question = state[\"user_input\"]\n",
    "        output = state[\"schema\"]\n",
    "        data_path = state[\"data_path\"]\n",
    "\n",
    "        table_path_dict = {str(i[\"table_name\"]):data_path+str(i[\"table_name\"])+\".csv\" for i in output[\"selected_columns\"]}\n",
    "\n",
    "        table_path = \"\"\n",
    "        for i in table_path_dict.keys():\n",
    "            table_path+=\"For table \"+i+\" use path \"+table_path_dict[i]+\"\\n\"\n",
    "        \n",
    "\n",
    "        prompt_path = state[\"prompt_path\"] + \"code_generation.txt\"\n",
    "\n",
    "        with open(prompt_path, 'r') as f:\n",
    "            code_generation_template = f.read()\n",
    "\n",
    "\n",
    "        code_generation_prompt = PromptTemplate(input_variables=[\"structured_json_output\", \"user_question\",\"table_path\",\"old_code\",\"traceback_error\"],\n",
    "                                                template=code_generation_template  )\n",
    "        \n",
    "        parser = JsonOutputParser()\n",
    "\n",
    "        code_chain = code_generation_prompt | llm | parser\n",
    "\n",
    "        output = code_chain.invoke({\n",
    "                            \"structured_json_output\": output,\n",
    "                            \"user_question\": user_question,\n",
    "                            \"table_path\":table_path,\n",
    "                            \"old_code\": state[\"pandas_code\"],\n",
    "                            \"traceback_error\":state[\"traceback_error\"]\n",
    "                            \n",
    "                            })\n",
    "        \n",
    "        state[\"chain_of_thought\"][\"Code Generation\"] = output[\"chain_of_thought\"]\n",
    "        state[\"pandas_code\"] = output['python_code']\n",
    "        state[\"code_execution_limit\"] -= 1\n",
    "        print(output)\n",
    "        return state\n",
    "    return code_generation_agent   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def code_execution_agent(state:State)->State:\n",
    "    \n",
    "    local_vars = {}\n",
    "    pandas_code = state[\"pandas_code\" ]\n",
    "    exec(pandas_code ,globals(),local_vars)\n",
    "    python_output = local_vars['final_output'][\"output\"]\n",
    "    error = local_vars['final_output']['traceback_error']\n",
    "    \n",
    "\n",
    "    state[\"execution_result\"] = python_output\n",
    "    state[\"traceback_error\"] = error\n",
    "\n",
    "    print(local_vars['final_output'])\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def create_pretty_print_agent(llm):\n",
    "    def pretty_print_agent(state:State)->State:\n",
    "\n",
    "        user_question = state[\"user_input\"]\n",
    "        python_output = state[\"execution_result\"]\n",
    "\n",
    "        prompt_path = state[\"prompt_path\"] + \"pretty_print.txt\"\n",
    "\n",
    "        with open(prompt_path, 'r') as f:\n",
    "            pretty_print_template = f.read()\n",
    "\n",
    "        pretty_print_prompt = PromptTemplate(\n",
    "            input_variables=[\"user_question\",\"output\"],\n",
    "            template=pretty_print_template )\n",
    "\n",
    "\n",
    "        chain = pretty_print_prompt | llm\n",
    "\n",
    "        output = chain.invoke({\n",
    "        \"user_question\":user_question,\n",
    "        \"output\":python_output })\n",
    "\n",
    "        state[\"bot_output\"] = output.content\n",
    "        print(output.content)\n",
    "\n",
    "        return state\n",
    "    return pretty_print_agent\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "def check_code_status(state:State)-> Literal[\"pretty_print_agent\", \"code_execution_agent\"]:\n",
    "\n",
    "    pandas_code = state[\"pandas_code\"] \n",
    "    if pandas_code is None:\n",
    "        return \"pretty_print_agent\"\n",
    "    else:\n",
    "        return \"code_execution_agent\"\n",
    "    \n",
    "def check_execution_status(state:State)-> Literal[\"pretty_print_agent\", \"code_generation_agent\"]:\n",
    "\n",
    "    execution_result = state[\"execution_result\"] \n",
    "    \n",
    "    state[\"code_execution_limit\"]\n",
    "    code_execution_limit = state[\"code_execution_limit\" ]\n",
    "\n",
    "    if execution_result  :\n",
    "        return \"pretty_print_agent\"\n",
    "    elif code_execution_limit == 0:\n",
    "        return \"pretty_print_agent\"\n",
    "    else:\n",
    "        return \"code_generation_agent\"\n",
    "\n",
    "\n",
    "\n",
    "model = LLMLoader()\n",
    "llm = model.load_google_model_flash2()\n",
    "builder  = StateGraph(State)\n",
    "\n",
    "\n",
    "schema_selection_agent= create_schema_selection_agent(llm)\n",
    "code_generation_agent = create_code_generation_agent(llm)\n",
    "pretty_print_agent = create_pretty_print_agent(llm)\n",
    " \n",
    "builder.add_node(schema_selection_agent,\"schema_selection_agent\")\n",
    "builder.add_node(code_generation_agent,\"code_generation_agent\")\n",
    "builder.add_node(code_execution_agent,\"code_execution_agent\")\n",
    "builder.add_node(pretty_print_agent,\"pretty_print_agent\")\n",
    "\n",
    "\n",
    "builder.add_edge(START,\"schema_selection_agent\")\n",
    "builder.add_edge(\"schema_selection_agent\",\"code_generation_agent\")\n",
    "#builder.add_edge(\"code_generation_agent\",\"code_execution_agent\")\n",
    "builder.add_conditional_edges(\"code_generation_agent\",check_code_status)\n",
    "builder.add_conditional_edges(\"code_execution_agent\",check_execution_status)\n",
    "#builder.add_edge(\"code_execution_agent\",\"pretty_print_agent\")\n",
    "builder.add_edge(\"pretty_print_agent\",END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd4a0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x105017980>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583609c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chain_of_thought': \"The user wants to find the person with the lowest salary and then compare that salary to the average salary of the department they belong to. To achieve this, I need to find the person with the minimum salary from the `resource_table`. Then, I need to find the average salary of the department that person belongs to from the `department_table`. Finally, I need to calculate the difference between the person's salary and the department's average salary. Therefore, I need to select the `name`, `salary`, and `department` columns from the `resource_table` and the `department` and `average_salary` columns from the `department_table`. A join is required to combine these two tables on the department column.\", 'selected_columns': [{'table_name': 'resource_table', 'column_names': ['name', 'salary', 'department']}, {'table_name': 'department_table', 'column_names': ['department', 'average_salary']}], 'joins': {'left_table': 'resource_table', 'right_table': 'department_table', 'left_column': 'department', 'right_column': 'department', 'join_type': 'inner'}, 'ambiguity_notes': None}\n",
      "{'chain_of_thought': \"The user is asking for the person with the lowest salary and the difference between their salary and their department's average salary. The structured JSON provides all the necessary information: the tables to use (`resource_table` and `department_table`), the columns to select from each table, and the join condition. The code will first read the data, select the relevant columns, perform the join, find the minimum salary, calculate the difference between the minimum salary and the department's average salary, and finally return the result.\", 'python_code': 'import pandas as pd\\nimport json\\nimport traceback\\n\\ntry:\\n    # Load dataframes (assuming they are already loaded)\\n    # resource_table = pd.read_csv(\"../data/resource_table.csv\")\\n    # department_table = pd.read_csv(\"../data/department_table.csv\")\\n\\n    # Select relevant columns\\n    resource_table = resource_table[[\\'name\\', \\'salary\\', \\'department\\']]\\n    department_table = department_table[[\\'department\\', \\'average_salary\\']]\\n\\n    # Perform inner join\\n    merged_df = pd.merge(resource_table, department_table, how=\\'inner\\', left_on=\\'department\\', right_on=\\'department\\')\\n\\n    # Find the person with the minimum salary\\n    min_salary = merged_df[\\'salary\\'].min()\\n    person_with_min_salary = merged_df[merged_df[\\'salary\\'] == min_salary]\\n\\n    if not person_with_min_salary.empty:\\n        person_name = person_with_min_salary[\\'name\\'].iloc[0]\\n        department_average_salary = person_with_min_salary[\\'average_salary\\'].iloc[0]\\n        salary_difference = person_with_min_salary[\\'salary\\'].iloc[0] - department_average_salary\\n\\n        result = {\\n            \\'person_with_lowest_salary\\': person_name,\\n            \\'salary_difference_from_department_average\\': salary_difference\\n        }\\n    else:\\n        result = {\\n            \\'person_with_lowest_salary\\': None,\\n            \\'salary_difference_from_department_average\\': None\\n        }\\n\\n    final_output = {\\n        \\'output\\': result,\\n        \\'traceback_error\\': None\\n    }\\n\\nexcept Exception as e:\\n    final_output = {\\n        \\'output\\': {},\\n        \\'traceback_error\\': traceback.format_exc()\\n    }\\n'}\n",
      "{'output': {}, 'traceback_error': 'Traceback (most recent call last):\\n  File \"<string>\", line 11, in <module>\\nNameError: name \\'resource_table\\' is not defined\\n'}\n",
      "{'chain_of_thought': \"The user wants to find the person with the lowest salary and compare it to their department's average salary. The structured JSON provides the necessary tables, columns, and join information. The previous attempt failed because the dataframes were not loaded before being used. This is corrected by loading the dataframes using the provided paths before selecting the columns and performing the join. The rest of the logic remains the same: find the minimum salary, identify the person with that salary, calculate the difference between their salary and their department's average, and return the result.\", 'python_code': 'import pandas as pd\\nimport json\\nimport traceback\\n\\ntry:\\n    # Load dataframes\\n    resource_table = pd.read_csv(\"../data/resource_table.csv\")\\n    department_table = pd.read_csv(\"../data/department_table.csv\")\\n\\n    # Select relevant columns\\n    resource_table = resource_table[[\\'name\\', \\'salary\\', \\'department\\']]\\n    department_table = department_table[[\\'department\\', \\'average_salary\\']]\\n\\n    # Perform inner join\\n    merged_df = pd.merge(resource_table, department_table, how=\\'inner\\', left_on=\\'department\\', right_on=\\'department\\')\\n\\n    # Find the person with the minimum salary\\n    min_salary = merged_df[\\'salary\\'].min()\\n    person_with_min_salary = merged_df[merged_df[\\'salary\\'] == min_salary]\\n\\n    if not person_with_min_salary.empty:\\n        person_name = person_with_min_salary[\\'name\\'].iloc[0]\\n        department_average_salary = person_with_min_salary[\\'average_salary\\'].iloc[0]\\n        salary_difference = person_with_min_salary[\\'salary\\'].iloc[0] - department_average_salary\\n\\n        result = {\\n            \\'person_with_lowest_salary\\': person_name,\\n            \\'salary_difference_from_department_average\\': salary_difference\\n        }\\n    else:\\n        result = {\\n            \\'person_with_lowest_salary\\': None,\\n            \\'salary_difference_from_department_average\\': None\\n        }\\n\\n    final_output = {\\n        \\'output\\': result,\\n        \\'traceback_error\\': None\\n    }\\n\\nexcept Exception as e:\\n    final_output = {\\n        \\'output\\': {},\\n        \\'traceback_error\\': traceback.format_exc()\\n    }\\n'}\n",
      "{'output': {'person_with_lowest_salary': 'Andrew Thomas 0579', 'salary_difference_from_department_average': np.float64(-12.402573529411764)}, 'traceback_error': None}\n",
      "The person with the lowest salary is Andrew Thomas 0579. His salary is $12.40 lower than the average salary in his department.\n",
      "The person with the lowest salary is Andrew Thomas 0579. His salary is $12.40 lower than the average salary in his department.\n"
     ]
    }
   ],
   "source": [
    "user_question = \"Which person has the lowest salary and how low is his salary compared to department average\"\n",
    "state = {\n",
    "    \"user_input\":user_question,  \n",
    "    \"agent_status\":{\"schema_selection_node\":True},\n",
    "    \"prompt_path\" : \"../prompt/\",\n",
    "    \"data_path\" : \"../data/\",\n",
    "    \"column_description_table\"  : \"../data/column_description_table.csv\",\n",
    "    \"pandas_code\" :\"\",\n",
    "    \"traceback_error\" : \"\",\n",
    "    \"chain_of_thought\" : {},\n",
    "    \"code_execution_limit\" : 3,\n",
    "    \"execution_result\"  : \"\"\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "    user_input : str           \n",
    "    optimized_prompt : str  = {}    \n",
    "    context : dict  = {}               \n",
    "    schema : {}  = {}              \n",
    "    ambiguity_flags : bool     = True    \n",
    "    pandas_code : str    = \"\"         \n",
    "    execution_result : str   = \"\"     \n",
    "    memory : list   = []                  \n",
    "    agent_status: dict  = {}\n",
    "    prompt_path : str = \"../prompt/\"\n",
    "    data_path : str = \"../data/\"\n",
    "    column_description_table : str = \"../data/column_description_table.csv\"\n",
    "    traceback_error : str = \"\"\n",
    "    chain_of_thought : {} = {}\n",
    "    bot_output : str = \"\"\n",
    "    code_execution_limit : int = 3\n",
    "          \n",
    "\n",
    "\n",
    "output = graph.invoke(state)\n",
    "print(output[\"bot_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39c58c8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'CompiledStateGraph' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;129m@graph\u001b[39m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmy_graph\u001b[39m(state: State):\n\u001b[32m      3\u001b[39m     state = schema_selection_agent(state)\n\u001b[32m      4\u001b[39m     state = code_generation_agent(state)\n",
      "\u001b[31mTypeError\u001b[39m: 'CompiledStateGraph' object is not callable"
     ]
    }
   ],
   "source": [
    "@graph()\n",
    "def my_graph(state: State):\n",
    "    state = schema_selection_agent(state)\n",
    "    state = code_generation_agent(state)\n",
    "\n",
    "    if check_code_status(state) == \"pretty_print_agent\":\n",
    "        state = pretty_print_agent(state)\n",
    "        return state\n",
    "    else:\n",
    "        state = code_execution_agent(state)\n",
    "\n",
    "    if check_execution_status(state) == \"pretty_print_agent\":\n",
    "        state = pretty_print_agent(state)\n",
    "    else:\n",
    "        state = code_generation_agent(state)  # Loop back\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5459f608",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langgraph.studio'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstudio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LangGraphStudio\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langgraph.studio'"
     ]
    }
   ],
   "source": [
    "from import LangGraphStudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce213e97",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'visualize' from 'langgraph.graph' (/Users/orion29/Documents/Projects/Query Bot/myenv/lib/python3.12/site-packages/langgraph/graph/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m visualize\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'visualize' from 'langgraph.graph' (/Users/orion29/Documents/Projects/Query Bot/myenv/lib/python3.12/site-packages/langgraph/graph/__init__.py)"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8153896",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'langgraph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mlanggraph\u001b[49m-studio\n",
      "\u001b[31mNameError\u001b[39m: name 'langgraph' is not defined"
     ]
    }
   ],
   "source": [
    "langgraph-lstudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c562b834",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'langgraph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mlanggraph\u001b[49m-studio\n",
      "\u001b[31mNameError\u001b[39m: name 'langgraph' is not defined"
     ]
    }
   ],
   "source": [
    "langgraph-studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1770d75d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langgraph.studio'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstudio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Studio\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langgraph.studio'"
     ]
    }
   ],
   "source": [
    "from langgraph.studio import Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5881a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "import pandas as pd\n",
    "from langgraph.graph import START,END,StateGraph\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from typing import TypedDict,Literal\n",
    "\n",
    "class LLMLoader:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def load_google_model_pro(self, temperature = 0):\n",
    "\n",
    "        load_dotenv()\n",
    "        os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCUNraO6zYI6dhyHWUKk3u_tXxx-uQgmCk\"\n",
    "\n",
    "        model = ChatGoogleGenerativeAI(\n",
    "                model=\"gemini-1.5-pro-latest\",\n",
    "                temperature=temperature,\n",
    "                max_tokens=None,\n",
    "                timeout=None,\n",
    "                max_retries=2,\n",
    "                # other params...\n",
    "            )\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def load_google_model_flash2(self, temperature = 0):\n",
    "\n",
    "        load_dotenv()\n",
    "        os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "        model = ChatGoogleGenerativeAI(\n",
    "                model=\"models/gemini-2.0-flash\",\n",
    "                temperature=temperature,\n",
    "                max_tokens=None,\n",
    "                timeout=None,\n",
    "                max_retries=2,\n",
    "                # other params...\n",
    "            )\n",
    "\n",
    "        return model\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "\n",
    "\n",
    "    user_input : str           \n",
    "    optimized_prompt : str  = {}    \n",
    "    context : dict  = {}               \n",
    "    schema : {}  = {}              \n",
    "    ambiguity_flags : bool     = True    \n",
    "    pandas_code : str    = \"\"         \n",
    "    execution_result : str   = \"\"     \n",
    "    memory : list   = []                  \n",
    "    agent_status: dict  = {}\n",
    "    prompt_path : str = \"../prompt/\"\n",
    "    data_path : str = \"../data/\"\n",
    "    column_description_table : str = \"../data/column_description_table.csv\"\n",
    "    traceback_error : str = \"\"\n",
    "    chain_of_thought : {} = {}\n",
    "    bot_output : str = \"\"\n",
    "    code_execution_limit : int = 3\n",
    "          \n",
    "          \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_schema_selection_agent(llm):\n",
    "    def schema_selection_agent(state : State )->State:\n",
    "\n",
    "        user_question = state[\"user_input\"]\n",
    "        column_description_table_path = state[\"column_description_table\"]\n",
    "        column_description_table = pd.read_csv(column_description_table_path)\n",
    "\n",
    "        prompt_path = state[\"prompt_path\"] + \"schema_selection.txt\"\n",
    "\n",
    "        with open(prompt_path, 'r') as f:\n",
    "            schema_selection_template = f.read()\n",
    "\n",
    "        table_schema = \"\"\n",
    "        for i,j in column_description_table.groupby(\"table_name\"):\n",
    "            j = j.reset_index(drop=True)\n",
    "            table_schema+=\"Table name : \"+str(i)+\"\\n\"\n",
    "            table_schema+=\"Table description : \"+str(j[\"table_description\"].unique()[0])+\"\\n\\n\"\n",
    "            table_schema+=f\"Column descripitions of table {i}: \\n\"\n",
    "            for k in range(len(j)):\n",
    "                l = j.iloc[k]\n",
    "                table_schema+= \"Column name :\"+str(l[\"column_name\"])+\"\\n\"\n",
    "                table_schema+= \"Column description :\"+str(l[\"column_description\"])+\"\\n\"\n",
    "                table_schema+= \"Column description :\"+str(l[\"typical_values\"])+\"\\n\"\n",
    "            table_schema +=\"\\n\\n\"\n",
    "\n",
    "        \n",
    "        schema_selection_prompt = PromptTemplate(\n",
    "                            input_variables=[\"user_question\",\"table_schema\"],\n",
    "                            template=schema_selection_template )\n",
    "        \n",
    "        parser = JsonOutputParser()\n",
    "\n",
    "        \n",
    "        schema_chain = schema_selection_prompt | llm | parser\n",
    "\n",
    "        schema_json = schema_chain.invoke({\n",
    "                \"table_schema\":table_schema,\n",
    "                \"user_question\":user_question})\n",
    "        \n",
    "        state[\"schema\"] = schema_json\n",
    "\n",
    "        state[\"chain_of_thought\"][\"Schema selection\"]  = schema_json['chain_of_thought']\n",
    "\n",
    "        print(schema_json)\n",
    "\n",
    "\n",
    "    #    schema = \"\"\n",
    "    #    for one_table in output[\"schema\"][\"selected_columns\"][:1]:\n",
    "    #        i = one_table[\"table_name\"]\n",
    "    #        j = column_description_table[column_description_table[\"table_name\"] == i].reset_index(drop=True)\n",
    "    #        schema+=\"Table name : \"+str(i)+\"\\n\"\n",
    "    #        schema+=\"Table description : \"+str(j[\"table_description\"].unique()[0])+\"\\n\\n\"\n",
    "    #        schema+=f\"Description of selected columns {i}: \\n\"\n",
    "    #        for k in range(len(j)):\n",
    "    #            l = j.iloc[k]\n",
    "    #            if l[\"column_name\"] in one_table[\"column_names\"]:\n",
    "    #                schema+= \"Column name :\"+str(l[\"column_name\"])+\"\\n\"\n",
    "    #                schema+= \"Column description :\"+str(l[\"column_description\"])+\"\\n\"\n",
    "    #                schema+= \"Column description :\"+str(l[\"typical_values\"])+\"\\n\"\n",
    "    #        schema +=\"\\n\\n\"\n",
    "\n",
    "        return state\n",
    "    return schema_selection_agent  \n",
    "\n",
    "\n",
    "def create_code_generation_agent(llm):\n",
    "    def code_generation_agent(state : State) -> State:\n",
    "        \n",
    "        user_question = state[\"user_input\"]\n",
    "        output = state[\"schema\"]\n",
    "        data_path = state[\"data_path\"]\n",
    "\n",
    "        table_path_dict = {str(i[\"table_name\"]):data_path+str(i[\"table_name\"])+\".csv\" for i in output[\"selected_columns\"]}\n",
    "\n",
    "        table_path = \"\"\n",
    "        for i in table_path_dict.keys():\n",
    "            table_path+=\"For table \"+i+\" use path \"+table_path_dict[i]+\"\\n\"\n",
    "        \n",
    "\n",
    "        prompt_path = state[\"prompt_path\"] + \"code_generation.txt\"\n",
    "\n",
    "        with open(prompt_path, 'r') as f:\n",
    "            code_generation_template = f.read()\n",
    "\n",
    "\n",
    "        code_generation_prompt = PromptTemplate(input_variables=[\"structured_json_output\", \"user_question\",\"table_path\",\"old_code\",\"traceback_error\"],\n",
    "                                                template=code_generation_template  )\n",
    "        \n",
    "        parser = JsonOutputParser()\n",
    "\n",
    "        code_chain = code_generation_prompt | llm | parser\n",
    "\n",
    "        output = code_chain.invoke({\n",
    "                            \"structured_json_output\": output,\n",
    "                            \"user_question\": user_question,\n",
    "                            \"table_path\":table_path,\n",
    "                            \"old_code\": state[\"pandas_code\"],\n",
    "                            \"traceback_error\":state[\"traceback_error\"]\n",
    "                            \n",
    "                            })\n",
    "        \n",
    "        state[\"chain_of_thought\"][\"Code Generation\"] = output[\"chain_of_thought\"]\n",
    "        state[\"pandas_code\"] = output['python_code']\n",
    "        state[\"code_execution_limit\"] -= 1\n",
    "        print(output)\n",
    "        return state\n",
    "    return code_generation_agent   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def code_execution_agent(state:State)->State:\n",
    "    \n",
    "    local_vars = {}\n",
    "    pandas_code = state[\"pandas_code\" ]\n",
    "    exec(pandas_code ,globals(),local_vars)\n",
    "    python_output = local_vars['final_output'][\"output\"]\n",
    "    error = local_vars['final_output']['traceback_error']\n",
    "    \n",
    "\n",
    "    state[\"execution_result\"] = python_output\n",
    "    state[\"traceback_error\"] = error\n",
    "\n",
    "    print(local_vars['final_output'])\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def create_pretty_print_agent(llm):\n",
    "    def pretty_print_agent(state:State)->State:\n",
    "\n",
    "        user_question = state[\"user_input\"]\n",
    "        python_output = state[\"execution_result\"]\n",
    "\n",
    "        prompt_path = state[\"prompt_path\"] + \"pretty_print.txt\"\n",
    "\n",
    "        with open(prompt_path, 'r') as f:\n",
    "            pretty_print_template = f.read()\n",
    "\n",
    "        pretty_print_prompt = PromptTemplate(\n",
    "            input_variables=[\"user_question\",\"output\"],\n",
    "            template=pretty_print_template )\n",
    "\n",
    "\n",
    "        chain = pretty_print_prompt | llm\n",
    "\n",
    "        output = chain.invoke({\n",
    "        \"user_question\":user_question,\n",
    "        \"output\":python_output })\n",
    "\n",
    "        state[\"bot_output\"] = output.content\n",
    "        print(output.content)\n",
    "\n",
    "        return state\n",
    "    return pretty_print_agent\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "def check_code_status(state:State)-> Literal[\"pretty_print_agent\", \"code_execution_agent\"]:\n",
    "\n",
    "    pandas_code = state[\"pandas_code\"] \n",
    "    if pandas_code is None:\n",
    "        return \"pretty_print_agent\"\n",
    "    else:\n",
    "        return \"code_execution_agent\"\n",
    "    \n",
    "def check_execution_status(state:State)-> Literal[\"pretty_print_agent\", \"code_generation_agent\"]:\n",
    "\n",
    "    execution_result = state[\"execution_result\"] \n",
    "    \n",
    "    state[\"code_execution_limit\"]\n",
    "    code_execution_limit = state[\"code_execution_limit\" ]\n",
    "\n",
    "    if execution_result  :\n",
    "        return \"pretty_print_agent\"\n",
    "    elif code_execution_limit == 0:\n",
    "        return \"pretty_print_agent\"\n",
    "    else:\n",
    "        return \"code_generation_agent\"\n",
    "\n",
    "\n",
    "\n",
    "model = LLMLoader()\n",
    "llm = model.load_google_model_flash2()\n",
    "builder  = StateGraph(State)\n",
    "\n",
    "\n",
    "schema_selection_agent= create_schema_selection_agent(llm)\n",
    "code_generation_agent = create_code_generation_agent(llm)\n",
    "pretty_print_agent = create_pretty_print_agent(llm)\n",
    " \n",
    "builder.add_node(schema_selection_agent,\"schema_selection_agent\")\n",
    "builder.add_node(code_generation_agent,\"code_generation_agent\")\n",
    "builder.add_node(code_execution_agent,\"code_execution_agent\")\n",
    "builder.add_node(pretty_print_agent,\"pretty_print_agent\")\n",
    "\n",
    "\n",
    "builder.add_edge(START,\"schema_selection_agent\")\n",
    "builder.add_edge(\"schema_selection_agent\",\"code_generation_agent\")\n",
    "#builder.add_edge(\"code_generation_agent\",\"code_execution_agent\")\n",
    "builder.add_conditional_edges(\"code_generation_agent\",check_code_status)\n",
    "builder.add_conditional_edges(\"code_execution_agent\",check_execution_status)\n",
    "#builder.add_edge(\"code_execution_agent\",\"pretty_print_agent\")\n",
    "builder.add_edge(\"pretty_print_agent\",END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
